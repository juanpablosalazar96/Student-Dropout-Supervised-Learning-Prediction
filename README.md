# Student Dropout Supervised Learning Prediction
**Background Context**

This project leverages supervised learning techniques to address student dropout, a persistent challenge in the education sector. High dropout rates can negatively affect student outcomes, institutional finances, and reputation. The project focuses on an education provider that supports international students through personalized learning, academic preparation programs, and digital learning tools. By identifying students at risk of dropping out, the goal is to enable early interventions and promote long-term student success.

**Objective**

The objective is to develop a predictive model that identifies students at risk of dropping out using supervised machine learning algorithms, including XGBoost and neural networks. The project encompasses data exploration, preprocessing, feature engineering, model development, and evaluation. Special attention is given to identifying key predictors and optimizing model performance to enable actionable insights and proactive student support strategies.

**Key Outcomes**
- The final models demonstrated strong predictive performance, with XGBoost consistently outperforming other models across multiple evaluation metrics.

- Adding relevant features significantly improved accuracy and AUC scores, highlighting the importance of high-quality, informative data.

- Regularization techniques (L1 and L2) successfully reduced overfitting in neural network models and improved generalization.

- Hyperparameter tuning showed limited performance gains, suggesting that future work could focus on feature selection, class imbalance handling, and expanding the model search space for refinement.

**Showcased Skills**
 - Supervised Machine Learning: Trained and evaluated advanced models, including XGBoost and neural networks for binary classification tasks.

 - Feature Engineering & Data Quality Analysis: Identified and added impactful features to enhance model accuracy and interpretability.

 - Model Evaluation & Tuning: Applied metrics such as AUC and accuracy; used L1/L2 regularization to prevent overfitting.

 - Critical Thinking & Strategic Insight: Assessed the trade-offs between model complexity and performance, and proposed practical improvements for future iterations.
